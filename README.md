# CodeceptJS Test Automation Framework (Playwright + REST + TypeScript)

This repository contains a modular automation framework built with [CodeceptJS](https://codecept.io/), [Playwright](https://playwright.dev/), and [TypeScript](https://www.typescriptlang.org/) to cover both WEB and API test scenarios. It includes Allure reporting, reusable helpers, and DRY principles for maintainability.

---

# Quick Start Guide

**Option 1: Download Without Git (ZIP Method)**

If you're not using Git, you can still run the project locally:

1. Go to the repository: https://github.com/QA-Gelo/saucedemo-reqres-test-automation
2. Click the green â€œCodeâ€ button â†’ â€œDownload ZIPâ€.
3. Extract the ZIP file.
4. Open the project folder in Visual Studio Code.

**Option 2: Clone Using Git**

1. Install Git for Windows Download from git-scm.com and install it. During setup, make sure to select:
    > â€œUse Git from the command line and also from 3rd-party softwareâ€
    > â€œCheckout Windows-style, commit Unix-style line endingsâ€ (default)
2. Open CMD or PowerShell. Press Win + R, type cmd, and hit Enter or search for PowerShell.
3. Run the clone command
    > git clone https://github.com/QA-Gelo/saucedemo-reqres-test-automation.git

## ðŸ“¦ Tech Stack

- CodeceptJS
- Playwright
- TypeScript
- REST Helper
- Allure Legacy Reporter

---

**Install Dependencies**

1. Download and install Nodejs v20.17.0 (LTS) version
2. Install jdk 17.0.12 and configure the JAVA_HOME variable (this is for creation and viewing of HTML report generated by allure)
3. Download latest version of Visual Studio Code
    > Install following vscode extension/s: Cucumber (Gherkin) Full Support
4. Open vscode and open the Project Directory.
5. In View > Terminal (**Launch Command Prompt not powershell**)
6. Initialize the project by running the command > npm install
    If by chance the dependecies are not installed, re-install the dependecies by running the follwing commands:
    > npm install --save-dev codeceptjs playwright
    > npm install @codeceptjs/allure-legacy --save-dev
    > npm install -g allure-commandline --save-dev

**Test Execution**

In the package.json under Scripts, the keywords for test execution are declared.
    "tests": "codeceptjs run --steps",
    "report": "allure generate output --clean && allure open",
    "test:web": "codeceptjs run --grep @web --plugins allure --steps",
    "test:api": "codeceptjs run --grep @api --plugins allure --steps",
    "test:features": "codeceptjs run --features",
    "test:headless": "HEADLESS=true codeceptjs run --features --plugins allure --steps",

To use these keywords, you need to prefix the keywords by "npm run"
    For example, we want to run all the web tests: 
        > Run the command: npm run test (use this to run all the test scenarios for web and api)

**Test Execution Logs/Reports**

After the test execution, test reports should be generated in the output folder.
    Run the following command/s:
    > allure generate output --clean -o allure-report (ensures previous report data is removed before generating a new one)
    > allure open (opens the generated allure html report for viewing)

Note:
1.  For the screenshot of failed test, allure also generate it's own screenshot that's why the screenshots of failed will be doubled.
    Screenshots genereted by allure have alphanumeric file name. Use the screenshots generated by codeceptjs which is named following
    the feature/test that failed.

2.  I deleted all the test results so the output folder is empty.

**Comments related to specific scenarios**

1. Saucedemo: Scenario_2
    > I keep the validation as is for the selecter item. As the user account was named as problem_user,
      the changing of the name of the added name is viewed as a system defect. Even though I can direct the result
      of the scenario to pass, I decided to keep it as is and let it fail as I viewed it as a defect.

2. Saucedemo: Scenario_3
    > As the default sorting of the item names are in A to Z, I set my test to validate the Z to A sorting of item names.

3. reqres: Scenario_2
    > In the API documentation, creation of new user response does not have a parameter for creation date.